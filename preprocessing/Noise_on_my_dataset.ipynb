{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M1PFjjmfGhBl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "K.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rarfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FNSS3D2GsZG",
        "outputId": "6d3f1f91-902c-4e75-dabd-2de88353dec3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import gdown\n",
        "import rarfile\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "# Corrected download URL format\n",
        "url = 'https://drive.google.com/uc?id=1YGe4VubSw5Pt1FrutEK0VgV7eKjcQ4sA'\n",
        "\n",
        "output_rar = '/content/rice.rar'\n",
        "gdown.download(url, output_rar, quiet=False, fuzzy=True)\n",
        "\n",
        "# Extract the RAR file\n",
        "try:\n",
        "    with rarfile.RarFile(output_rar, 'r') as rar_ref:\n",
        "        rar_ref.extractall('/content')\n",
        "except rarfile.NotRarFile:\n",
        "    print(\"The downloaded file is not a valid RAR file.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MtCRTsqG_84",
        "outputId": "d857e832-447e-480a-e758-70020d4c0591"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1YGe4VubSw5Pt1FrutEK0VgV7eKjcQ4sA\n",
            "From (redirected): https://drive.google.com/uc?id=1YGe4VubSw5Pt1FrutEK0VgV7eKjcQ4sA&confirm=t&uuid=25e39c17-cd13-4d51-8dd1-9abec85b4fb8\n",
            "To: /content/rice.rar\n",
            "100%|██████████| 1.87G/1.87G [00:23<00:00, 80.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the extracted dataset original folder\n",
        "dataset = '/content/rice'"
      ],
      "metadata": {
        "id": "3g8aZf8JHEvd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import rarfile\n",
        "\n",
        "# File ID from the provided Google Drive link\n",
        "file_id = \"1fOFS9igMw1Vo8n64IZBBJHp2NXFi_tT3\"\n",
        "file_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "output_rar = '/content/preprocessed_data.rar'\n",
        "gdown.download(file_url, output_rar, quiet=False)\n",
        "\n",
        "# Extract the RAR file\n",
        "try:\n",
        "    with rarfile.RarFile(output_rar, 'r') as rar_ref:\n",
        "        rar_ref.extractall('/content')\n",
        "    print(\"Extraction completed successfully.\")\n",
        "except rarfile.NotRarFile:\n",
        "    print(\"The downloaded file is not a valid RAR file.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7-U_AaUHJnD",
        "outputId": "e6610652-1a3c-4d42-ab38-e9485fdc9df8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1fOFS9igMw1Vo8n64IZBBJHp2NXFi_tT3\n",
            "From (redirected): https://drive.google.com/uc?id=1fOFS9igMw1Vo8n64IZBBJHp2NXFi_tT3&confirm=t&uuid=382ea72d-06c5-4e03-a74c-77acb28fcd88\n",
            "To: /content/preprocessed_data.rar\n",
            "100%|██████████| 1.22G/1.22G [00:11<00:00, 111MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the extracted dataset original folder\n",
        "dataset = '/content/preprocessed_data'"
      ],
      "metadata": {
        "id": "im-RDRg_IzQ6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import numpy as np\n",
        "\n",
        "# Paths to original and preprocessed datasets\n",
        "original_dataset_path = '/content/rice'\n",
        "preprocessed_dataset_path = '/content/preprocessed_data'\n",
        "\n",
        "# Function to calculate PSNR\n",
        "def calculate_psnr(original, processed):\n",
        "    mse = np.mean((original - processed) ** 2)\n",
        "    if mse == 0:  # No noise\n",
        "        return 100\n",
        "    psnr = 10 * np.log10(255.0 ** 2 / mse)\n",
        "    return psnr\n",
        "\n",
        "# Function to calculate SSIM\n",
        "def calculate_ssim(original, processed):\n",
        "    return ssim(original, processed, data_range=processed.max() - processed.min(), multichannel=True)\n",
        "\n",
        "# Loop through images in both folders\n",
        "results = []\n",
        "for root, dirs, files in os.walk(original_dataset_path):\n",
        "    for file_name in files:\n",
        "        # Load original and preprocessed images\n",
        "        original_img_path = os.path.join(root, file_name)\n",
        "        processed_img_path = original_img_path.replace(original_dataset_path, preprocessed_dataset_path)\n",
        "\n",
        "        if os.path.exists(processed_img_path):\n",
        "            original_img = cv2.imread(original_img_path)\n",
        "            processed_img = cv2.imread(processed_img_path)\n",
        "\n",
        "            # Resize images to match if needed\n",
        "            if original_img.shape != processed_img.shape:\n",
        "                processed_img = cv2.resize(processed_img, (original_img.shape[1], original_img.shape[0]))\n",
        "\n",
        "            # Calculate PSNR and SSIM\n",
        "            psnr_value = calculate_psnr(original_img, processed_img)\n",
        "            ssim_value = calculate_ssim(original_img, processed_img)\n",
        "\n",
        "            # Append results\n",
        "            results.append({\n",
        "                'file': file_name,\n",
        "                'psnr': psnr_value,\n",
        "                'ssim': ssim_value\n",
        "            })\n",
        "            print(f\"File: {file_name}, PSNR: {psnr_value}, SSIM: {ssim_value}\")\n"
      ],
      "metadata": {
        "id": "AVCoTbznJAIA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Path to the original dataset\n",
        "dataset_path = '/content/rice'\n",
        "\n",
        "# Function to calculate PSNR\n",
        "def calculate_psnr(image1, image2):\n",
        "    mse = np.mean((image1 - image2) ** 2)\n",
        "    if mse == 0:  # Identical images\n",
        "        return 100\n",
        "    psnr = 10 * np.log10(255.0 ** 2 / mse)\n",
        "    return psnr\n",
        "\n",
        "# Function to calculate SSIM\n",
        "def calculate_ssim(image1, image2):\n",
        "    return ssim(image1, image2, data_range=image2.max() - image2.min(), multichannel=True)\n",
        "\n",
        "# Lists to store PSNR and SSIM values\n",
        "psnr_values = []\n",
        "ssim_values = []\n",
        "\n",
        "# Process images in each class folder within Train, Validation, and Test\n",
        "for split in [\"Train\", \"Validation\", \"Test\"]:\n",
        "    for cls_folder in os.listdir(os.path.join(dataset_path, split)):\n",
        "        class_path = os.path.join(dataset_path, split, cls_folder)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        # Load images and calculate PSNR, SSIM between consecutive pairs for baseline\n",
        "        images = [cv2.imread(os.path.join(class_path, img)) for img in os.listdir(class_path) if img.endswith(('.jpg', '.png'))]\n",
        "        images = [img for img in images if img is not None]\n",
        "\n",
        "        for i in range(len(images) - 1):\n",
        "            img1, img2 = images[i], images[i + 1]\n",
        "\n",
        "            # Resize images to the same shape if needed\n",
        "            if img1.shape != img2.shape:\n",
        "                img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "            # Calculate PSNR and SSIM\n",
        "            psnr = calculate_psnr(img1, img2)\n",
        "            psnr_values.append(psnr)\n",
        "\n",
        "            ssim_score = calculate_ssim(img1, img2)\n",
        "            ssim_values.append(ssim_score)\n",
        "\n",
        "# Plotting PSNR and SSIM values\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot PSNR\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(len(psnr_values)), psnr_values, label=\"PSNR\", color='blue', marker='o')\n",
        "plt.xlabel(\"Image Pair Index\")\n",
        "plt.ylabel(\"PSNR (dB)\")\n",
        "plt.title(\"PSNR across Original Dataset\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot SSIM\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(len(ssim_values)), ssim_values, label=\"SSIM\", color='green', marker='o')\n",
        "plt.xlabel(\"Image Pair Index\")\n",
        "plt.ylabel(\"SSIM\")\n",
        "plt.title(\"SSIM across Original Dataset\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print average PSNR and SSIM\n",
        "print(f\"Average PSNR: {np.mean(psnr_values):.2f}\")\n",
        "print(f\"Average SSIM: {np.mean(ssim_values):.4f}\")\n"
      ],
      "metadata": {
        "id": "oTsrJ4peR3a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Paths to original and preprocessed datasets\n",
        "original_dataset_path = '/content/rice'\n",
        "preprocessed_dataset_path = '/content/preprocessed_data'\n",
        "\n",
        "# Lists to store PSNR and SSIM values for each preprocessing type\n",
        "psnr_values = {\"Gamma Correction\": [], \"Histogram Equalization\": [], \"Contrast Stretching\": [], \"CLAHE\": []}\n",
        "ssim_values = {\"Gamma Correction\": [], \"Histogram Equalization\": [], \"Contrast Stretching\": [], \"CLAHE\": []}\n",
        "\n",
        "# Define a function to calculate PSNR\n",
        "def calculate_psnr(image1, image2):\n",
        "    mse = np.mean((image1 - image2) ** 2)\n",
        "    if mse == 0:  # Identical images\n",
        "        return 100\n",
        "    psnr = 10 * np.log10(255.0 ** 2 / mse)\n",
        "    return psnr\n",
        "\n",
        "# Define a function to calculate SSIM\n",
        "def calculate_ssim(image1, image2):\n",
        "    return ssim(image1, image2, data_range=image2.max() - image2.min(), multichannel=True)\n",
        "\n",
        "# Loop through each image in the original dataset\n",
        "for split in [\"Train\", \"Validation\", \"Test\"]:\n",
        "    for cls_folder in os.listdir(os.path.join(original_dataset_path, split)):\n",
        "        class_path_original = os.path.join(original_dataset_path, split, cls_folder)\n",
        "        class_path_processed = os.path.join(preprocessed_dataset_path, split, cls_folder)\n",
        "\n",
        "        if not os.path.isdir(class_path_original) or not os.path.isdir(class_path_processed):\n",
        "            continue\n",
        "\n",
        "        for img_file in os.listdir(class_path_original):\n",
        "            original_img_path = os.path.join(class_path_original, img_file)\n",
        "            processed_img_path = os.path.join(class_path_processed, img_file)\n",
        "\n",
        "            # Load both original and processed images\n",
        "            original_img = cv2.imread(original_img_path)\n",
        "            processed_img = cv2.imread(processed_img_path)\n",
        "\n",
        "            # Skip if either image is missing\n",
        "            if original_img is None or processed_img is None:\n",
        "                continue\n",
        "\n",
        "            # Resize processed image to match original if needed\n",
        "            if original_img.shape != processed_img.shape:\n",
        "                processed_img = cv2.resize(processed_img, (original_img.shape[1], original_img.shape[0]))\n",
        "\n",
        "            # Identify preprocessing type based on folder naming\n",
        "            if \"gamma_corrected\" in processed_img_path:\n",
        "                preprocessing_type = \"Gamma Correction\"\n",
        "            elif \"histogram_equalized\" in processed_img_path:\n",
        "                preprocessing_type = \"Histogram Equalization\"\n",
        "            elif \"contrast_stretched\" in processed_img_path:\n",
        "                preprocessing_type = \"Contrast Stretching\"\n",
        "            elif \"clahe_eq\" in processed_img_path:\n",
        "                preprocessing_type = \"CLAHE\"\n",
        "            else:\n",
        "                continue  # Skip unrecognized preprocessing\n",
        "\n",
        "            # Calculate PSNR and SSIM between original and processed image\n",
        "            psnr = calculate_psnr(original_img, processed_img)\n",
        "            ssim_score = calculate_ssim(original_img, processed_img)\n",
        "\n",
        "            # Append the scores to the respective preprocessing lists\n",
        "            psnr_values[preprocessing_type].append(psnr)\n",
        "            ssim_values[preprocessing_type].append(ssim_score)\n",
        "\n",
        "# Plotting PSNR and SSIM values for each preprocessing type\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot PSNR for each preprocessing type\n",
        "plt.subplot(1, 2, 1)\n",
        "for key in psnr_values:\n",
        "    plt.plot(range(len(psnr_values[key])), psnr_values[key], label=f\"{key} PSNR\", marker='o')\n",
        "plt.xlabel(\"Image Index\")\n",
        "plt.ylabel(\"PSNR (dB)\")\n",
        "plt.title(\"PSNR for Each Preprocessing Type\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot SSIM for each preprocessing type\n",
        "plt.subplot(1, 2, 2)\n",
        "for key in ssim_values:\n",
        "    plt.plot(range(len(ssim_values[key])), ssim_values[key], label=f\"{key} SSIM\", marker='o')\n",
        "plt.xlabel(\"Image Index\")\n",
        "plt.ylabel(\"SSIM\")\n",
        "plt.title(\"SSIM for Each Preprocessing Type\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print average PSNR and SSIM for each preprocessing type\n",
        "for key in psnr_values:\n",
        "    print(f\"{key} - Average PSNR: {np.mean(psnr_values[key]):.2f}\")\n",
        "    print(f\"{key} - Average SSIM: {np.mean(ssim_values[key]):.4f}\")\n"
      ],
      "metadata": {
        "id": "sxAvRwzhwtCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Paths to original and preprocessed datasets\n",
        "original_dataset_path = '/content/rice'\n",
        "preprocessed_dataset_path = '/content/preprocessed_data'\n",
        "\n",
        "# Function to count files in each class subfolder\n",
        "def count_files(base_path, dataset_name):\n",
        "    print(f\"\\nFile count for {dataset_name}:\")\n",
        "    total_files = 0\n",
        "    for root, _, files in os.walk(base_path):\n",
        "        # Only count files in leaf class subfolders, ignore main folders like Train, Test, Validation\n",
        "        if any(subdir in root for subdir in ['Train', 'Validation', 'Test']):\n",
        "            num_files = len(files)\n",
        "            print(f\"{os.path.basename(root)}: {num_files} files\")\n",
        "            total_files += num_files\n",
        "    print(f\"Total files in {dataset_name}: {total_files}\")\n",
        "\n",
        "# Count files in both datasets\n",
        "count_files(original_dataset_path, \"Original Dataset\")\n",
        "count_files(preprocessed_dataset_path, \"Preprocessed Dataset\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Mb6MchDflqX",
        "outputId": "c8b75cbc-2fa0-41c5-e023-62f39d4f9589"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "File count for Original Dataset:\n",
            "Train: 0 files\n",
            "healthy: 1491 files\n",
            "brown_spot: 1480 files\n",
            "rice_hispa: 1461 files\n",
            "bacterial_leaf_blight: 1386 files\n",
            "leaf_blast: 1801 files\n",
            "Validation: 0 files\n",
            "healthy: 110 files\n",
            "brown_spot: 110 files\n",
            "Rice Hispa: 110 files\n",
            "bacterial_leaf_blight: 110 files\n",
            "leaf_blast: 110 files\n",
            "Test: 0 files\n",
            "healthy: 281 files\n",
            "brown_spot: 270 files\n",
            "Rice Hispa: 115 files\n",
            "bacterial_leaf_blight: 266 files\n",
            "leaf_blast: 252 files\n",
            "Total files in Original Dataset: 9353\n",
            "\n",
            "File count for Preprocessed Dataset:\n",
            "Train: 0 files\n",
            "healthy: 5964 files\n",
            "brown_spot: 5920 files\n",
            "rice_hispa: 5844 files\n",
            "bacterial_leaf_blight: 5544 files\n",
            "leaf_blast: 7204 files\n",
            "Validation: 0 files\n",
            "healthy: 440 files\n",
            "brown_spot: 440 files\n",
            "Rice Hispa: 440 files\n",
            "bacterial_leaf_blight: 440 files\n",
            "leaf_blast: 440 files\n",
            "Test: 0 files\n",
            "healthy: 1124 files\n",
            "brown_spot: 1080 files\n",
            "Rice Hispa: 460 files\n",
            "bacterial_leaf_blight: 1064 files\n",
            "leaf_blast: 1008 files\n",
            "Total files in Preprocessed Dataset: 37412\n"
          ]
        }
      ]
    }
  ]
}