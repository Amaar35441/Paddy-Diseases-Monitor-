from tensorflow.keras import backend as K
K.clear_session()

!pip install rarfile

import os
import gdown
import rarfile

# Download file again in case it wasn't extracted correctly
file_id = '1dyorpmEWOBd2V0b9UNwkJm3EDvLJU1FE'
url = f'https://drive.google.com/uc?id={file_id}'
output_rar = '/content/rice-leaf-diseases5c.rar'

# Download the RAR file
gdown.download(url, output_rar, quiet=False)

# Verify and extract the RAR file
extracted_path = '/content/rice-leaf-diseases5c'
if rarfile.is_rarfile(output_rar):
    with rarfile.RarFile(output_rar, 'r') as rar_ref:
        rar_ref.extractall('/content')
    print("Extraction successful.")
else:
    print("The downloaded file is not a valid RAR file.")

# List contents of /content to check if extraction worked as expected
print("Contents of /content after extraction:", os.listdir('/content'))

# Check if the expected data directory now exists
if os.path.exists(extracted_path):
    print("Data directory found:", extracted_path)
else:
    print("Data directory not found. Check if it was extracted to a different path.")


import os

# Path of the extracted directory (replace with actual directory if different)
extracted_dir = '/content/rice-leaf-diseases-detection-'

# Check if directory exists and list its contents
if os.path.exists(extracted_dir):
    print(f"Contents of '{extracted_dir}':", os.listdir(extracted_dir))
else:
    print(f"Directory '{extracted_dir}' not found.")


# Path of the extracted directory (replace with actual directory if different)
extracted_dir = '/content/rice-leaf-diseases-detection-'

from keras.models import Model
from keras.layers import Input, Conv2D, DepthwiseConv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense

def mobilenetv2(input_shape=(224, 224, 3), num_classes=5, alpha=1.0):
    """
    MobileNetV2 implementation with customizable input shape, number of classes, and width multiplier (alpha).

    Args:
        input_shape (tuple): Shape of input images (height, width, channels).
        num_classes (int): Number of output classes.
        alpha (float): Width multiplier for model scaling.

    Returns:
        Model: Compiled MobileNetV2 model.
    """
    def inverted_residual_block(inputs, expansion, filters, stride, alpha, block_id):
        """Defines an inverted residual block."""
        in_channels = inputs.shape[-1]
        pointwise_filters = int(filters * alpha)

        x = Conv2D(expansion * in_channels, kernel_size=1, padding='same', use_bias=False, name=f"expand_conv_{block_id}")(inputs)
        x = BatchNormalization(name=f"expand_bn_{block_id}")(x)
        x = ReLU(6.0, name=f"expand_relu_{block_id}")(x)

        x = DepthwiseConv2D(kernel_size=3, strides=stride, padding='same', use_bias=False, name=f"depthwise_conv_{block_id}")(x)
        x = BatchNormalization(name=f"depthwise_bn_{block_id}")(x)
        x = ReLU(6.0, name=f"depthwise_relu_{block_id}")(x)

        x = Conv2D(pointwise_filters, kernel_size=1, padding='same', use_bias=False, name=f"project_conv_{block_id}")(x)
        x = BatchNormalization(name=f"project_bn_{block_id}")(x)

        if stride == 1 and in_channels == pointwise_filters:
            x = inputs + x  # Residual connection

        return x

    inputs = Input(shape=input_shape)

    # Initial convolution layer
    x = Conv2D(int(32 * alpha), kernel_size=3, strides=2, padding='same', use_bias=False, name='conv1')(inputs)
    x = BatchNormalization(name='conv1_bn')(x)
    x = ReLU(6.0, name='conv1_relu')(x)

    # Inverted residual blocks
    x = inverted_residual_block(x, expansion=1, filters=16, stride=1, alpha=alpha, block_id=1)
    x = inverted_residual_block(x, expansion=6, filters=24, stride=2, alpha=alpha, block_id=2)
    x = inverted_residual_block(x, expansion=6, filters=24, stride=1, alpha=alpha, block_id=3)
    x = inverted_residual_block(x, expansion=6, filters=32, stride=2, alpha=alpha, block_id=4)
    x = inverted_residual_block(x, expansion=6, filters=32, stride=1, alpha=alpha, block_id=5)
    x = inverted_residual_block(x, expansion=6, filters=32, stride=1, alpha=alpha, block_id=6)

    # Additional blocks can be added here for a complete MobileNetV2 implementation

    # Global Average Pooling
    x = GlobalAveragePooling2D(name='global_avg_pool')(x)

    # Output layer
    outputs = Dense(num_classes, activation='softmax', name='output')(x)

    # Build model
    mobilenetv2_model = Model(inputs=inputs, outputs=outputs, name='MobileNetV2')

    # Compile the model
    mobilenetv2_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    return mobilenetv2_model

# Example: Building and summarizing the MobileNetV2 model
model = mobilenetv2(input_shape=(224, 224, 3), num_classes=5, alpha=1.0)
model.summary()

# Import required libraries
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
)
import seaborn as sns

# Define dataset directory
data_dir = '/content/rice-leaf-diseases-detection-'  # Adjust path as needed
classes = ['bacterial_leaf_blight', 'brown_spot', 'healthy', 'leaf_blast', 'rice_hispa']

# ImageDataGenerators
train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Create data generators
train_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, 'train'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse',
    shuffle=True
)

val_generator = val_datagen.flow_from_directory(
    os.path.join(data_dir, 'val'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse',
    shuffle=False
)

test_generator = test_datagen.flow_from_directory(
    os.path.join(data_dir, 'test'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse',
    shuffle=False
)

# Define and compile the hybrid model
model = hybrid_mobilenetv2_inceptionv3(input_shape=(224, 224, 3), num_classes=5, alpha=1.0, leaky_alpha=0.01)
# Train the hybrid model
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=50,  # Adjust number of epochs based on dataset size
    batch_size=32
)

# Plot training history
def plot_training_history(history):
    plt.figure(figsize=(12, 5))

    # Plot loss
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Loss Over Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Plot accuracy
    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Accuracy Over Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()
    plt.show()

# Call the function to visualize training history
plot_training_history(history)

# Evaluate the hybrid model on the test set
def evaluate_model(test_generator, model, classes, title="Performance"):
    y_test_pred = model.predict(test_generator)
    y_test_pred = np.argmax(y_test_pred, axis=1)

    precision = precision_score(test_generator.labels, y_test_pred, average='weighted')
    recall = recall_score(test_generator.labels, y_test_pred, average='weighted')
    f1 = f1_score(test_generator.labels, y_test_pred, average='weighted')
    accuracy = accuracy_score(test_generator.labels, y_test_pred)

    print(f"\n{title}")
    print("Precision:", precision)
    print("Recall:", recall)
    print("F1 Score:", f1)
    print("Accuracy:", accuracy)

    # Confusion matrix
    confusion = confusion_matrix(test_generator.labels, y_test_pred)
    confusion_df = pd.DataFrame(confusion, index=classes, columns=classes)
    print("Confusion Matrix:\n", confusion_df)

    # Plot confusion matrix as heatmap
    plt.figure(figsize=(8, 6))
    sns.heatmap(confusion_df, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix: {title}')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

# Evaluate the model
evaluate_model(test_generator, model, classes, title="Hybrid Model Performance on Test Data")
