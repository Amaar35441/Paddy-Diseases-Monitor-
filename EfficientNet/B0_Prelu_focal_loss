from tensorflow.keras import backend as K
K.clear_session()


!pip install rarfile



import os
import gdown
import rarfile

# Download file again in case it wasn't extracted correctly
file_id = '1dyorpmEWOBd2V0b9UNwkJm3EDvLJU1FE'
url = f'https://drive.google.com/uc?id={file_id}'
output_rar = '/content/rice-leaf-diseases5c.rar'

# Download the RAR file
gdown.download(url, output_rar, quiet=False)

# Verify and extract the RAR file
extracted_path = '/content/rice-leaf-diseases5c'
if rarfile.is_rarfile(output_rar):
    with rarfile.RarFile(output_rar, 'r') as rar_ref:
        rar_ref.extractall('/content')
    print("Extraction successful.")
else:
    print("The downloaded file is not a valid RAR file.")

# List contents of /content to check if extraction worked as expected
print("Contents of /content after extraction:", os.listdir('/content'))

# Check if the expected data directory now exists
if os.path.exists(extracted_path):
    print("Data directory found:", extracted_path)
else:
    print("Data directory not found. Check if it was extracted to a different path.")



# Path of the extracted directory (replace with actual directory if different)
extracted_dir = '/content/rice-leaf-diseases-detection-'



import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, Model, regularizers
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Directory for the dataset
data_dir = '/content/rice-leaf-diseases-detection-'

# Data Augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

val_test_datagen = ImageDataGenerator(rescale=1./255)

# Load data using ImageDataGenerator
train_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, 'train'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',  # One-hot encoding for label smoothing
    shuffle=True
)

val_generator = val_test_datagen.flow_from_directory(
    os.path.join(data_dir, 'val'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

test_generator = val_test_datagen.flow_from_directory(
    os.path.join(data_dir, 'test'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

# Define Focal Loss as an optional loss function
class FocalLoss(tf.keras.losses.Loss):
    def __init__(self, gamma=2.0, alpha=0.25):
        super(FocalLoss, self).__init__()
        self.gamma = gamma
        self.alpha = alpha

    def call(self, y_true, y_pred):
        y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)
        y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)
        cross_entropy = -y_true * tf.math.log(y_pred + tf.keras.backend.epsilon())
        weights = self.alpha * tf.pow(1 - y_pred, self.gamma)
        return tf.reduce_sum(weights * cross_entropy, axis=-1)

# Load EfficientNet-B0 without pre-trained weights
base_model = EfficientNetB0(weights=None, include_top=False, input_shape=(224, 224, 3))

# Freeze the base model initially
base_model.trainable = False

# Add custom layers
inputs = tf.keras.Input(shape=(224, 224, 3))
x = base_model(inputs, training=False)
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)  # L2 Regularization
x = Dropout(0.5)(x)  # Dropout
outputs = Dense(5, activation='softmax')(x)

model = Model(inputs, outputs)

# Compile the model with label smoothing
model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss=CategoricalCrossentropy(label_smoothing=0.1),
    metrics=['accuracy']
)

# Train the added layers first
history = model.fit(train_generator, epochs=10, validation_data=val_generator)

# Unfreeze the base model for fine-tuning
base_model.trainable = True

# Compile the model with a reduced learning rate
model.compile(
    optimizer=Adam(learning_rate=1e-5),
    loss=CategoricalCrossentropy(label_smoothing=0.1),  # Label smoothing
    metrics=['accuracy']
)

# Fine-tune the entire model
history_fine = model.fit(train_generator, epochs=20, validation_data=val_generator)

# Plot Training Results
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'] + history_fine.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'] + history_fine.history['val_loss'], label='Validation Loss')
plt.title('Loss Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'] + history_fine.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'] + history_fine.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

# Evaluate the model
def evaluate_model(generator, model, classes):
    y_true = generator.labels
    y_pred_probs = model.predict(generator)
    y_pred = np.argmax(y_pred_probs, axis=1)

    # Metrics
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted')
    recall = recall_score(y_true, y_pred, average='weighted')
    f1 = f1_score(y_true, y_pred, average='weighted')

    print(f"Accuracy: {accuracy:.2f}")
    print(f"Precision: {precision:.2f}")
    print(f"Recall: {recall:.2f}")
    print(f"F1 Score: {f1:.2f}")

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred)
    cm_df = pd.DataFrame(cm, index=classes, columns=classes)
    print("Confusion Matrix:\n", cm_df)

# Test the Model
evaluate_model(
    test_generator,
    model,
    ['bacterial_leaf_blight', 'brown_spot', 'healthy', 'leaf_blast', 'rice_hispa']
)

