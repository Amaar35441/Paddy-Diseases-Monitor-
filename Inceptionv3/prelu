from tensorflow.keras import backend as K
K.clear_session()

!pip install rarfile


import os
import gdown
import rarfile

# Download file again in case it wasn't extracted correctly
file_id = '1dyorpmEWOBd2V0b9UNwkJm3EDvLJU1FE'
url = f'https://drive.google.com/uc?id={file_id}'
output_rar = '/content/rice-leaf-diseases5c.rar'

# Download the RAR file
gdown.download(url, output_rar, quiet=False)

# Verify and extract the RAR file
extracted_path = '/content/rice-leaf-diseases5c'
if rarfile.is_rarfile(output_rar):
    with rarfile.RarFile(output_rar, 'r') as rar_ref:
        rar_ref.extractall('/content')
    print("Extraction successful.")
else:
    print("The downloaded file is not a valid RAR file.")

# List contents of /content to check if extraction worked as expected
print("Contents of /content after extraction:", os.listdir('/content'))

# Check if the expected data directory now exists
if os.path.exists(extracted_path):
    print("Data directory found:", extracted_path)
else:
    print("Data directory not found. Check if it was extracted to a different path.")


# Path of the extracted directory (replace with actual directory if different)
extracted_dir = '/content/rice-leaf-diseases-detection-'


# Import libraries
import os
import random
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.layers import PReLU  # Import PReLU
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
)

# Directory for the dataset
data_dir = '/content/rice-leaf-diseases-detection-'

# Define the custom InceptionV3 model with PReLU activations
base_model = InceptionV3(
    weights=None,               # No pre-trained weights
    include_top=False,          # Exclude top layer to modify the model
    input_shape=(224, 224, 3),  # Input image shape
)

# Add PReLU activation to the base model
x = base_model.output
x = PReLU()(x)  # Applying PReLU after the base model output

# Add a global average pooling layer
x = tf.keras.layers.GlobalAveragePooling2D()(x)

# Add a fully connected (dense) layer with PReLU activation
x = tf.keras.layers.Dense(1024)(x)
x = PReLU()(x)  # Applying PReLU to the dense layer

# Output layer with softmax activation for multi-class classification
predictions = tf.keras.layers.Dense(5, activation='softmax')(x)

# Create the final model
model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# ImageDataGenerators
train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Data generators for training, validation, and testing
train_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, 'train'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse',
    shuffle=True
)

val_generator = val_datagen.flow_from_directory(
    os.path.join(data_dir, 'val'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse',
    shuffle=False
)

test_generator = test_datagen.flow_from_directory(
    os.path.join(data_dir, 'test'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse',
    shuffle=False
)

# Training the model
history = model.fit(train_generator, epochs=10, validation_data=val_generator)

# Plot training results
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

# Helper function to evaluate the model on given test generator
def evaluate_model(test_generator, model, classes, title="Performance"):
    y_test_pred = model.predict(test_generator)
    y_test_pred = np.argmax(y_test_pred, axis=1)

    precision = precision_score(test_generator.labels, y_test_pred, average='weighted')
    recall = recall_score(test_generator.labels, y_test_pred, average='weighted')
    f1 = f1_score(test_generator.labels, y_test_pred, average='weighted')
    accuracy = accuracy_score(test_generator.labels, y_test_pred)

    print(f"\n{title}")
    print("Precision:", precision)
    print("Recall:", recall)
    print("F1 Score:", f1)
    print("Accuracy:", accuracy)

    # Confusion matrix
    confusion = confusion_matrix(test_generator.labels, y_test_pred)
    confusion_df = pd.DataFrame(confusion, index=classes, columns=classes)
    print("Confusion Matrix:\n", confusion_df)

    # Plot confusion matrix as heatmap
    plt.figure(figsize=(8, 6))
    sns.heatmap(confusion_df, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix: {title}')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

# Evaluate model on the test set
evaluate_model(test_generator, model, [
    'bacterial_leaf_blight', 'brown_spot', 'healthy', 'leaf_blast', 'rice_hispa'], title="Performance on Test Data")



