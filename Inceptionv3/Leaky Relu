from tensorflow.keras import backend as K
K.clear_session()


!pip install rarfile


import os
import gdown
import rarfile

# Download file again in case it wasn't extracted correctly
file_id = '1dyorpmEWOBd2V0b9UNwkJm3EDvLJU1FE'
url = f'https://drive.google.com/uc?id={file_id}'
output_rar = '/content/rice-leaf-diseases5c.rar'

# Download the RAR file
gdown.download(url, output_rar, quiet=False)

# Verify and extract the RAR file
extracted_path = '/content/rice-leaf-diseases5c'
if rarfile.is_rarfile(output_rar):
    with rarfile.RarFile(output_rar, 'r') as rar_ref:
        rar_ref.extractall('/content')
    print("Extraction successful.")
else:
    print("The downloaded file is not a valid RAR file.")

# List contents of /content to check if extraction worked as expected
print("Contents of /content after extraction:", os.listdir('/content'))

# Check if the expected data directory now exists
if os.path.exists(extracted_path):
    print("Data directory found:", extracted_path)
else:
    print("Data directory not found. Check if it was extracted to a different path.")



import os

# Path of the extracted directory (replace with actual directory if different)
extracted_dir = '/content/rice-leaf-diseases-detection-'

# Check if directory exists and list its contents
if os.path.exists(extracted_dir):
    print(f"Contents of '{extracted_dir}':", os.listdir(extracted_dir))
else:
    print(f"Directory '{extracted_dir}' not found.")




# Path of the extracted directory (replace with actual directory if different)
extracted_dir = '/content/rice-leaf-diseases-detection-'



# Import necessary libraries
import tensorflow as tf
from tensorflow.keras.layers import (
    Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout, BatchNormalization, LeakyReLU, Input
)
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os

# Custom Inception Block with LeakyReLU
def inception_block(x, filters):
    f1, f3r, f3, f5r, f5, proj = filters

    # 1x1 Convolution
    conv1 = Conv2D(f1, (1, 1), padding='same')(x)
    conv1 = BatchNormalization()(conv1)
    conv1 = LeakyReLU(alpha=0.01)(conv1)

    # 1x1 followed by 3x3 Convolution
    conv3 = Conv2D(f3r, (1, 1), padding='same')(x)
    conv3 = BatchNormalization()(conv3)
    conv3 = LeakyReLU(alpha=0.01)(conv3)
    conv3 = Conv2D(f3, (3, 3), padding='same')(conv3)
    conv3 = BatchNormalization()(conv3)
    conv3 = LeakyReLU(alpha=0.01)(conv3)

    # 1x1 followed by 5x5 Convolution
    conv5 = Conv2D(f5r, (1, 1), padding='same')(x)
    conv5 = BatchNormalization()(conv5)
    conv5 = LeakyReLU(alpha=0.01)(conv5)
    conv5 = Conv2D(f5, (5, 5), padding='same')(conv5)
    conv5 = BatchNormalization()(conv5)
    conv5 = LeakyReLU(alpha=0.01)(conv5)

    # 3x3 MaxPooling followed by 1x1 Convolution
    pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)
    pool = Conv2D(proj, (1, 1), padding='same')(pool)
    pool = BatchNormalization()(pool)
    pool = LeakyReLU(alpha=0.01)(pool)

    # Concatenate all branches
    output = tf.keras.layers.concatenate([conv1, conv3, conv5, pool])
    return output

# Custom InceptionV3 Model
def custom_inception_v3(input_shape=(224, 224, 3), num_classes=5):
    inputs = Input(shape=input_shape)

    # Initial Layers
    x = Conv2D(32, (3, 3), strides=(2, 2), padding='valid')(inputs)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.01)(x)
    x = Conv2D(32, (3, 3), padding='valid')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.01)(x)
    x = Conv2D(64, (3, 3), padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.01)(x)
    x = MaxPooling2D((3, 3), strides=(2, 2))(x)

    # Inception Blocks
    x = inception_block(x, [64, 48, 64, 64, 96, 32])
    x = inception_block(x, [64, 48, 64, 64, 96, 64])
    x = MaxPooling2D((3, 3), strides=(2, 2))(x)

    x = inception_block(x, [128, 96, 128, 96, 128, 128])
    x = inception_block(x, [128, 96, 128, 96, 128, 128])
    x = MaxPooling2D((3, 3), strides=(2, 2))(x)

    # Fully Connected Layers
    x = Flatten()(x)
    x = Dense(1024)(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.01)(x)
    x = Dropout(0.5)(x)

    x = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs, x)

    # Compile Model
    model.compile(optimizer=Adam(learning_rate=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    return model

# Instantiate the Model
model = custom_inception_v3(input_shape=(224, 224, 3), num_classes=5)
model.summary()


# Import libraries
import os
import random
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
)

# Directory for the dataset
data_dir = '/content/rice-leaf-diseases-detection-'

# ImageDataGenerators
train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Data generators
train_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, 'train'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse',
    shuffle=True
)

val_generator = val_datagen.flow_from_directory(
    os.path.join(data_dir, 'val'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse',
    shuffle=False
)

test_generator = test_datagen.flow_from_directory(
    os.path.join(data_dir, 'test'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='sparse',
    shuffle=False
)

# Train the Model
history = model.fit(train_generator, epochs=40, validation_data=val_generator)

# Plot Results
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

# Evaluate Model
def evaluate_model(test_generator, model, classes, title="Performance"):
    y_test_pred = model.predict(test_generator)
    y_test_pred = np.argmax(y_test_pred, axis=1)

    precision = precision_score(test_generator.labels, y_test_pred, average='weighted')
    recall = recall_score(test_generator.labels, y_test_pred, average='weighted')
    f1 = f1_score(test_generator.labels, y_test_pred, average='weighted')
    accuracy = accuracy_score(test_generator.labels, y_test_pred)

    print(f"\n{title}")
    print("Precision:", precision)
    print("Recall:", recall)
    print("F1 Score:", f1)
    print("Accuracy:", accuracy)

    # Confusion Matrix
    confusion = confusion_matrix(test_generator.labels, y_test_pred)
    confusion_df = pd.DataFrame(confusion, index=classes, columns=classes)
    print("Confusion Matrix:\n", confusion_df)

    # Heatmap
    plt.figure(figsize=(8, 6))
    sns.heatmap(confusion_df, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix: {title}')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

evaluate_model(test_generator, model, [
    'bacterial_leaf_blight', 'brown_spot', 'healthy', 'leaf_blast', 'rice_hispa'], title="Performance on Test Data")


