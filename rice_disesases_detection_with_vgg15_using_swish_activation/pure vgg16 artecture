from tensorflow.keras import backend as K
K.clear_session()


!pip install rarfile



import os
import gdown
import rarfile

# Download file again in case it wasn't extracted correctly
file_id = '1dyorpmEWOBd2V0b9UNwkJm3EDvLJU1FE'
url = f'https://drive.google.com/uc?id={file_id}'
output_rar = '/content/rice-leaf-diseases5c.rar'

# Download the RAR file
gdown.download(url, output_rar, quiet=False)

# Verify and extract the RAR file
extracted_path = '/content/rice-leaf-diseases5c'
if rarfile.is_rarfile(output_rar):
    with rarfile.RarFile(output_rar, 'r') as rar_ref:
        rar_ref.extractall('/content')
    print("Extraction successful.")
else:
    print("The downloaded file is not a valid RAR file.")

# List contents of /content to check if extraction worked as expected
print("Contents of /content after extraction:", os.listdir('/content'))

# Check if the expected data directory now exists
if os.path.exists(extracted_path):
    print("Data directory found:", extracted_path)
else:
    print("Data directory not found. Check if it was extracted to a different path.")



# Path of the extracted directory (replace with actual directory if different)
extracted_dir = '/content/rice-leaf-diseases-detection-'



import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras import Sequential
from tensorflow.keras.layers import (
    Conv2D, MaxPooling2D, Flatten, Dense, Activation
)
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.activations import swish
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Dataset Directory
data_dir = '/content/rice-leaf-diseases-detection-'  # Update this path to your dataset directory

# VGG16 Architecture with Swish Activation
model = Sequential()

# Block 1
model.add(Conv2D(64, (3, 3), padding='same', input_shape=(224, 224, 3)))
model.add(Activation(swish))
model.add(Conv2D(64, (3, 3), padding='same'))
model.add(Activation(swish))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Block 2
model.add(Conv2D(128, (3, 3), padding='same'))
model.add(Activation(swish))
model.add(Conv2D(128, (3, 3), padding='same'))
model.add(Activation(swish))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Block 3
model.add(Conv2D(256, (3, 3), padding='same'))
model.add(Activation(swish))
model.add(Conv2D(256, (3, 3), padding='same'))
model.add(Activation(swish))
model.add(Conv2D(256, (3, 3), padding='same'))
model.add(Activation(swish))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Block 4
model.add(Conv2D(512, (3, 3), padding='same'))
model.add(Activation(swish))
model.add(Conv2D(512, (3, 3), padding='same'))
model.add(Activation(swish))
model.add(Conv2D(512, (3, 3), padding='same'))
model.add(Activation(swish))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Block 5
model.add(Conv2D(512, (3, 3), padding='same'))
model.add(Activation(swish))
model.add(Conv2D(512, (3, 3), padding='same'))
model.add(Activation(swish))
model.add(Conv2D(512, (3, 3), padding='same'))
model.add(Activation(swish))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Fully connected layers
model.add(Flatten())
model.add(Dense(4096))
model.add(Activation(swish))
model.add(Dense(4096))
model.add(Activation(swish))
model.add(Dense(5, activation='softmax'))  # Output layer for 5 classes

# Print model summary
model.summary()

# Compile the model
model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# ImageDataGenerators
train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Data generators for training, validation, and testing
train_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, 'train'),
    target_size=(224, 224),
    batch_size=16,
    class_mode='sparse',
    shuffle=True
)

val_generator = val_datagen.flow_from_directory(
    os.path.join(data_dir, 'val'),
    target_size=(224, 224),
    batch_size=16,
    class_mode='sparse',
    shuffle=False
)

test_generator = test_datagen.flow_from_directory(
    os.path.join(data_dir, 'test'),
    target_size=(224, 224),
    batch_size=16,
    class_mode='sparse',
    shuffle=False
)

# Training the model
history = model.fit(
    train_generator,
    epochs=10,  # 10 epochs for demonstration
    validation_data=val_generator
)

# Plot training results
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

# Evaluate the model on the test set
def evaluate_model(test_generator, model, class_labels):
    y_pred = model.predict(test_generator)
    y_pred_classes = np.argmax(y_pred, axis=1)

    precision = precision_score(test_generator.labels, y_pred_classes, average='weighted')
    recall = recall_score(test_generator.labels, y_pred_classes, average='weighted')
    f1 = f1_score(test_generator.labels, y_pred_classes, average='weighted')
    accuracy = accuracy_score(test_generator.labels, y_pred_classes)

    print("\nTest Performance:")
    print("Accuracy:", accuracy)
    print("Precision:", precision)
    print("Recall:", recall)
    print("F1 Score:", f1)

    # Confusion Matrix
    confusion = confusion_matrix(test_generator.labels, y_pred_classes)
    confusion_df = pd.DataFrame(confusion, index=class_labels, columns=class_labels)
    print("\nConfusion Matrix:\n", confusion_df)

# Class labels (update these as per your dataset)
class_labels = ['bacterial_leaf_blight', 'brown_spot', 'healthy', 'leaf_blast', 'rice_hispa']

evaluate_model(test_generator, model, class_labels)

